9/21/2025:

- First booting on jetson orin nano (from Dr. Min). Connected Display to display port, mouse and keyboard to usb port. Everythings works fine.
	> The board is from yahboom which is flashed by yahboom variant of operating system by default. need to flash jetpack separately.
- Tried to attach antenna while orin nano is running cause a screen to go black for a second, the screen is back on. Then the wifi & bluetooth card turned extreamly hot. the keyboard and mouse connected to orin nano no long works. the orin nano still boot up and looks fine on the screen showing yahboom operating system.

encountered issue:
- inserting antenna while orin nano is on cause some form of short circuit and burned the wifi card and somehow mess with USB bus system. 
	> correct way to do: 	must turn orin nano off while inserting any connection or dealing with hardware.
	> solution: 		no much to do. will get a new jetson orin nano development kit tomorrow from Micro Center.


9/22/2025: 

What happened:

- Got new Jetson orin nano.

Encountered issue when flashing: 
- follow a video: https://youtu.be/BaRdpSXU6EM?si=EiEW-Ai79cL45F1M. 
	> when he unplug jumper to exit from recovery mode, you must do so at that time too.
	> no ip address needed for this version of SDK manager (not sure if there will be problem later).



- Flashed and install jetpack into ssd using SDK manager (seems to be successful).


Encountered issue:
- after booted up jetpack, chromium and firefox doesn't work.
	> solution: rollback snap/snapd version and hold for automatic update (holding for old version software is not recommended) need to find better solution
	> command to solve: $ snap download snapd --revision=24724
			    $ sudo snap ack snapd_24724.assert
			    $ sudo snap install snapd_24724.snap
			    $ sudo sudo snap refresh --hold snapd

	> solution link from nvidia forum: https://forums.developer.nvidia.com/t/neither-chromium-nor-firefox-work-with-my-jetson-orin-nano/338669


9/23/2025:

- installed docker, jtop

- found out that jtop cannot detect jetpack, this raise more suspicious about jetpack installation.

- add current user "orinanao?" into docker group

- git clone a jetson-container repository which has a lot of docker image for jetson such as stable diffusion.



- installed camera into jetson orin nano.


- git clone CSI-Camera repo to test the camera.
	> follow: 

- initially doesn't work. camera is not detected.
	> solution: use jetson-IO utility and enable IMX477
		- on terminal run: sudo /opt/nvidia/jetson-io/jetson-io.py
		- then choose "Configure Jetson 24pin CSI Connector"
		- then choose "Configure for compatible hardware"
		= then choose "Camera IMX477-A and IMX219-C"
		= follow though and reboot.


- Camera run at 1080P at 60Hz. has three main mode, day mode, night mode and day mode with IR-Cut unintentionally trigger make live-image more red.


9/25/2025:

- create a manual with step in detail, instruciton, encountered issue, and solution on overleaf. Also push this to github repo too. hasn't found a way to fully intgrate it into github repo yet and hasn't found a way to view .tex file as pdf in github yet. 



10/01/2025:

- tried to pull deepstream docker. 
	> deepstream version must compatible with jetpack version which for nano, jetpack 6.x is latest. 
	> as of today, jetpack 6.2.2, L4T36.4.4, deepstream-l47 7.0 works.

	> deepstream for jetson is called deepstream-l4t.



- command to run deepstream docker from nvidia:
	docker run --runtime nvidia --rm -it   --network host    -v /home/orinnano/DMS/Driver-attentiveness-monitoring-system/deepstream_workspace:/workspace -w /workspace    -v /tmp/.X11-unix:/tmp/.X11-unix    -e DISPLAY=$DISPLAY    nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch



	docker run --runtime nvidia --rm -it \
   --network host \
   --device /dev/video0 \
   --device /dev/nvhost-ctrl \
   --device /dev/nvhost-ctrl-gpu \
   --device /dev/nvhost-prof-gpu \
   --device /dev/nvmap \
   -v /home/orinnano/DMS/Driver-attentiveness-monitoring-system/deepstream_workspace:/workspace -w /workspace \
   -v /tmp/.X11-unix:/tmp/.X11-unix \
   -e DISPLAY=$DISPLAY \
   nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch 


- despite we were able to pull a live image from camera at host device, inside a deepstream docker, we cannot pull a live image camera.

- try pulling live image from camera on host device, run command below it shows up a live image from camera: 
	gst-launch-1.0 nvarguscamerasrc ! nveglglessink


- now try pull live image from camera in deepstream, run command below:
	docker run --runtime nvidia --rm -it \
   --network host \
   --device /dev/video0 \
   -v /home/orinnano/DMS/Driver-attentiveness-monitoring-system/deepstream_workspace:/workspace -w /workspace \
   -v /tmp/.X11-unix:/tmp/.X11-unix \
   -e DISPLAY=$DISPLAY \
   nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch


	command above should create a deepstream container, command below will try to pull up a live image from camera:
	gst-launch-1.0 nvarguscamerasrc ! nveglglessink



	> solution on pulling live image from camera inside docker: need to mount the real socket path so that docker container can connect to Argus. the path is: /tmp/argus_socket.

	> to properly create docker container with mounting argus socket use command below:

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



xhost +si:localuser:root

sudo docker run --runtime nvidia --rm -it --privileged \
  --network host \
  --device /dev/video0 \
  --device /dev/media0 \
  -v /tmp/argus_socket:/tmp/argus_socket \
  -v /run/dbus:/run/dbus \
  -v /tmp/.X11-unix:/tmp/.X11-unix \
  -e DISPLAY=$DISPLAY \
  nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch \
  gst-launch-1.0 nvarguscamerasrc ! nveglglessink



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

from command above we can extract functionality as below

allow privilage access (just in case, might not necessary):
	xhost +si:localuser:root


create container:
	docker run --runtime nvidia --rm -it --privileged \
  --network host \
  --device /dev/video0 \
  --device /dev/media0 \
  -v /tmp/argus_socket:/tmp/argus_socket \
  -v /run/dbus:/run/dbus \
  -v /tmp/.X11-unix:/tmp/.X11-unix \
  -e DISPLAY=$DISPLAY \
  nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch



try pull up camera:

gst-launch-1.0 nvarguscamerasrc ! nveglglessink



update version of container creation command:


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

docker run --gpus all --runtime nvidia --rm -it \
  --network host \
  --device /dev/video0 \
  --device /dev/media0 \
  -v /tmp/argus_socket:/tmp/argus_socket \
  -v /run/dbus:/run/dbus \
  -v /tmp/.X11-unix:/tmp/.X11-unix \
  -e DISPLAY=$DISPLAY \
  -v /home/orinnano/DMS/Driver-attentiveness-monitoring-system:/workspace -w /workspace \
  nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
command to run camera:

  deepstream-app -c config_camera_live_image.txt




- despite the correct command as shown above, with the dummy config below it successfully pulled up live image from camera in deepstream. 
	

	> important: source0: type=5, sink0: type=2. for more detail visit: https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#source-group. go to deepstream reference application - deepstream-app -> configuration groups.

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>.


[application]
enable-perf-measurement=1
perf-measurement-interval-sec=5

[tiled-display]
enable=0   # disable tiler

[source0]
enable=1
type=5			# CSI-Camera
camera-id=0
camera-width=1920
camera-height=1080
camera-fps-n=30
camera-fps-d=1

[streammux]
batch-size=1
width=1920
height=1080
batched-push-timeout=40000

[sink0]
enable=1
type=2          # EGL preview window
sync=0


^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^




- pulling live image from camera into deepstream app is done. 



- now try to import a face detection model


	> a model can be downloaded from nvidia NGC catalog for example: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/facenet?version=pruned_quantized_v2.0.1. for faceDetect/facenet

	> download a zip file and copy into the mounted workspace from host to docker container.


	> was able to run a deepstream app, a window with live image show up but it couldn't detect anything.

- since we will be install alot of thing. we will create a docker file. 
	
	> dockerfile location: DMS/Driver-attentiveness-monitorting-system/dockerfiles/Dockerfile.v1

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Dockerfile.v1 content >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	
# Start from DeepStream 7.0 Triton container
FROM nvcr.io/nvidia/deepstream-l4t:7.0-triton-multiarch

# Install dependencies
RUN apt-get update && apt-get install -y \
    wget curl python3-pip unzip \
    && rm -rf /var/lib/apt/lists/*

# Install NGC CLI (ARM64 version 4.5.2)
RUN wget --content-disposition \
    https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/4.5.2/files/ngccli_arm64.zip \
    -O ngccli_arm64.zip && \
    unzip ngccli_arm64.zip && \
    rm ngccli_arm64.zip && \
    chmod u+x ngc-cli/ngc && \
    mv ngc-cli /usr/local/bin/ && \
    ln -s /usr/local/bin/ngc-cli/ngc /usr/local/bin/ngc

# Install TAO Toolkit Converter for Jetson (JetPack 6.0, ARM64)
RUN ngc registry resource download-version nvidia/tao/tao-converter:v5.1.0_jp6.0_aarch64 && \
    cd /opt/nvidia/deepstream/deepstream-7.0/tao-converter_vv5.1.0_jp6.0_aarch64 && \
    chmod +x tao-converter && \
    mv tao-converter /usr/local/bin/ && \
    cd / && rm -rf /opt/nvidia/deepstream/deepstream-7.0/tao-converter_vv5.1.0_jp6.0_aarch64

# Set default workdir
WORKDIR /workspace
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	> link to download NGC CLI: https://org.ngc.nvidia.com/setup/installers/cli


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Command to build Docker image from dockerfile >>>>>>>>>>>>>>>>>>
docker build -t deepstreem:7.0-v1 -f Dockerfile.v1 .
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



- succesfully create docker image using dockerfile and build command above.




10/5/2025


tried to pull facedetectir, followed nvidia catalog and russian youtube video.


- nvidia catalog nolong provide .etle and config.txt file in deepstream 7.0

- russian guy use deepstream 5.1

	> we can try deepstream5.1 and download appropriate TAO converter version for it to try

	> we can try deepstream 7.0 with .etle and config.txt file from deepstream 5.1


10/07/2025:


- after turned on jetson, there is an update of some nvidia package, after update and reboot camera is not detected again.
	> after the update, L4T version is 36.4.7 now.
	> seems like after the update it reset the camera setting that we choose IMX477 at the beginning, need to repeat that step
	> sudo /opt/nvidia/jetson-io/jetson-io.py > set to IMX219 and IMX477 then follow through and reboot.


- try using .etlt file and config.txt file from deepstream5.1 in deepstream7.0
	> basically the .etlt file is legacy tensorflow/uff-based model. but on newer jetpack, tensorrt, cuda, it nolong support old uff parser.

	> solution, use deepstream 5.1 or find more suitable model than face detect ir.



10/12/2025:


- try using mediapipe instead for development purpose, cross platform. and getting result/verifying algorithm then will export to deepstream later for performance if need to.

- try installing vscode on jetpack.
  > follow this link: https://hackmd.io/@YungHuiHsu/H1klNXmk2?utm_source=preview-mode&utm_medium=rec

- try to create a new docker image for mediapipe development tools
	> first the docker image is based on latest l4t version available which is r36.2.0 (check on https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-base/tags?version=r36.2.0)
  > follow tutorial on https://eranfeit.net/how-to-install-mediapipe-on-the-jetson-nano/ and https://www.youtube.com/watch?v=ij9bIET4rCU 
  > successfully build and image using this docker file


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Dockerfile.v1 for mediapipe content >>>>>>>>>>>>>>>>>>
# ===========================================================
#  MediaPipe Dev Environment (JetPack 7 / L4T r36.4.7)
#  Always install latest packages, then record versions
# ===========================================================

FROM nvcr.io/nvidia/l4t-base:r36.2.0

LABEL maintainer="Khongmeng Kormoua"
LABEL description="MediaPipe + OpenCV + Bazel dev image (latest packages with version manifest)"

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
WORKDIR /workspace

# -----------------------------------------------------------
# 1. System + Python deps
# -----------------------------------------------------------
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential cmake unzip pkg-config git curl wget nano \
    python3 python3-pip python3-dev python3-opencv \
    ffmpeg libsm6 libxext6 libgl1-mesa-glx \
    openjdk-11-jdk protobuf-compiler libprotobuf-dev libopencv-dev \
    libjpeg-dev libpng-dev libtiff-dev mesa-utils \
    && rm -rf /var/lib/apt/lists/*

RUN python3 -m pip install --upgrade pip setuptools wheel
RUN pip install numpy absl-py matplotlib opencv-python-headless protobuf tqdm

# -----------------------------------------------------------
# 2. Bazelisk
# -----------------------------------------------------------
RUN LATEST=$(curl -s https://api.github.com/repos/bazelbuild/bazelisk/releases/latest \
      | grep browser_download_url | grep linux-arm64 | cut -d '"' -f 4) \
 && wget $LATEST -O /usr/local/bin/bazel \
 && chmod +x /usr/local/bin/bazel

# -----------------------------------------------------------
# 3. Clone MediaPipe
# -----------------------------------------------------------
RUN git clone https://github.com/google/mediapipe.git
WORKDIR /workspace/mediapipe

# -----------------------------------------------------------
# 4. Environment variables
# -----------------------------------------------------------
ENV CUDA_HOME=/usr/local/cuda
# ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}
ENV LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:/usr/local/cuda/lib64:/usr/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu/tegra
ENV PATH=/usr/local/cuda/bin:${PATH}

# -----------------------------------------------------------
# 5. Record versions of all components
# -----------------------------------------------------------
# RUN mkdir -p /workspace/version_logs && \
#     echo "===== BUILD INFO =====" > /workspace/version_logs/version_manifest.txt && \
#     date >> /workspace/version_logs/version_manifest.txt && \
#     echo "\n--- JetPack / L4T ---" >> /workspace/version_logs/version_manifest.txt && \
#     cat /etc/nv_tegra_release >> /workspace/version_logs/version_manifest.txt && \
#     echo "\n--- Bazelisk ---" >> /workspace/version_logs/version_manifest.txt && \
#     bazel version >> /workspace/version_logs/version_manifest.txt || true && \
#     echo "\n--- Git commits ---" >> /workspace/version_logs/version_manifest.txt && \
#     cd /workspace/mediapipe && git log -1 >> /workspace/version_logs/version_manifest.txt && \
#     echo "\n--- APT packages ---" >> /workspace/version_logs/version_manifest.txt && \
#     apt list --installed >> /workspace/version_logs/version_manifest.txt && \
#     echo "\n--- PIP packages ---" >> /workspace/version_logs/version_manifest.txt && \
#     pip freeze >> /workspace/version_logs/version_manifest.txt

CMD ["bash"]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



- using docker consume time in debugging alot of thing. so from now will try not using docker.


- first install conda Environment
  > run:
    # Install prerequisites
    sudo apt update
    cd ~

    # Download latest Miniforge3 installer (ARM64 build)
    wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-aarch64.sh

    # Install to your home directory
    bash Miniforge3-Linux-aarch64.sh

    > to create/activate/deactivate conda environment use: 
    conda create -n <ENV_NAME> python==3.11
      > python==3.11 just for mediapipe

    conda activate <ENV_NAME>

    conda deactivate


- follow this youtube video: https://www.youtube.com/watch?v=LF7Lgz4_lus

- the camera config for 24 pin at one point is set back to imx219 again, need to repeat a solution just like before.



11/12/2025:




= to initialize miniforge3
	source ~/miniforge3/bin/activate

- use guild from medium, is able to get head pos and eye gaze.




11/24/2025:


- try to get camera to works
  > issue: if we install mediapipe full package like what we did in conda/mediapipe environment, a pip opencv will be installed and it will be used which this version of opencv doesn't support Gstream, etc stuff that jetson use.
  > solution: use the opencv package that support jetson packaga, which can be installed by 
    sudo apt install python3-opencv libopencv-dev
    
    + conda create -n mp python=3.10
    + conda activate mp 
    + sudo apt install python3-opencv
    + ln -s /usr/lib/python3/dist-packages/cv2 $CONDA_PREFIX/lib/python3.10/site-packages/
    + pip install mediapipe (this failed)



    + conda deactivate -> exit (do untill we exit from conda completely, no (base) in front of the terminal)
    + python3 -c "import cv2; print(cv2.__file__)"
    + source ~/miniforge3/bin/activate
    + python3 -c "import cv2; print(cv2.__file__)"
    + conda activate mp
    + python3 -c "import cv2; print(cv2.__file__)"  (this will show no module name cv2)


    + python3 --version (this should give python 3.10.x   if it give newer version, we need to downgrade)
    + mkdir -p $CONDA_PREFIX/lib/python3.10/site-packages
    + ln -s /usr/lib/python3/dist-packages/cv2.cpython-310-aarch64-linux-gnu.so $CONDA_PREFIX/lib/python3.10/site-packages/cv2.so
    + ln -s /usr/lib/python3/dist-packages/cv2 $CONDA_PREFIX/lib/python3.10/site-packages/cv2   (this doesn't work but seem to be optional)

    > now in mp environment, a command below should give output like /home/orinnano/miniforge3/envs/mp/lib/python3.10/site-packages/cv2.so
      + python3 -c "import cv2; print(cv2.__file__)"


    > now a command below should give "True"
      + python3 -c "import cv2; print('GStreamer' in cv2.getBuildInformation())"

    > simple_camera.py should work in this environment.

  > now  we have mp environment that camera works but this environment failed to install mediapipe earlier.
    > issue: because no opencv from pip installed?
    > solution: install mediapipe with no dependence and install dependence manually.
    
      + pip install mediapipe=0.10.18 --no-deps
      + pip install absl-py attrs protobuf flatbuffers sounddevice (it will show and error with dependence that is not install but keep continue)

      now try 
        > python3 -c "import mediapipe as mp; print(mp.__version__)"
            if it shows 0.10.18 then it is good to go. if it shows "No module nhamed 'matplotlib' then proceed command below

      > pip install matplotlib==3.5.3

      now try 
        > python3 -c "import mediapipe as mp; print(mp.__version__)"   (now it should shows 0.10.18)


  > now mp environment should be ready to run gaze_v5_camera.py succesfully  